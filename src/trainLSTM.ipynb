{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5c86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy tensorflow scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb423019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from tensorflow.keras.models import Sequential, load_model # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "\n",
    "from layers.embedding import EmbeddingLayer\n",
    "from layers.rnn.bidirectionalRNN import BidirectionalRNN\n",
    "from layers.rnn.unidirectionalRNN import UnidirectionalRNN\n",
    "from layers.lstm.unidirectionalLSTM import UnidirectionalLSTM\n",
    "from layers.dense import DenseLayer\n",
    "\n",
    "from something.model import Model\n",
    "from something.rnn import RNN\n",
    "from something.lstm import LSTM\n",
    "from utils.evaluate import evaluate_model\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13c0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "valid = pd.read_csv('data/valid.csv')\n",
    "train['label'] = train['label'].map({'neutral': 0, 'positive': 1, 'negative': 2}).astype(np.float32)\n",
    "test['label'] = test['label'].map({'neutral': 0, 'positive': 1, 'negative': 2}).astype(np.float32)\n",
    "valid['label'] = valid['label'].map({'neutral': 0, 'positive': 1, 'negative': 2}).astype(np.float32)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)                         # python random\n",
    "np.random.seed(seed)                      # numpy\n",
    "tf.random.set_seed(seed)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc80393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2796\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")  # Reserve a token for unknown words\n",
    "tokenizer.fit_on_texts(train['text'].values) \n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding (index 0 is reserved)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2834b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "max_length = 100  # Maximum length of input sequences\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train['text'].values)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid['text'].values)\n",
    "valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "test_sequences = tokenizer.texts_to_sequences(test['text'].values)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding (index 0 is reserved)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5935407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Macro F1 Score: 0.1844\n",
      "Embedding weights shape: (2796, 100)\n",
      "LSTM weights shape: [(100, 64), (16, 64), (64,)]\n",
      "Dense weights shape: (16, 3), (3,)\n",
      "Initializing EmbeddingLayer with vocab_size=2796, embedding_dim=100, initializer=zeros\n",
      "Predicting with batch size: 32, input shape: (400, 100)\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 247,    7,  288,  ...,    0,    0,    0],\n",
      "        [ 495,  132,  534,  ...,    0,    0,    0],\n",
      "        [2236,   85,   26,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  14,    3,   20,  ...,    0,    0,    0],\n",
      "        [ 107,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 534,  637, 1806,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    6,   43,  ...,    0,    0,    0],\n",
      "        [  28,  321,  181,  ...,    0,    0,    0],\n",
      "        [ 201,    5,    7,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  10, 1445,  438,  ...,    0,    0,    0],\n",
      "        [  32,   28,  157,  ...,    0,    0,    0],\n",
      "        [ 107,  570,  571,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   6,  316,   97,  ...,    0,    0,    0],\n",
      "        [ 293,    1, 1806,  ...,    0,    0,    0],\n",
      "        [  25,  107,  333,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 484,   80,  973,  ...,    0,    0,    0],\n",
      "        [   5,  118, 1011,  ...,    0,    0,    0],\n",
      "        [   5,  201,    7,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Macro F1 Score: 0.1844\n",
      "Embedding weights shape: (2796, 100)\n",
      "LSTM weights shape: [(100, 64), (16, 64), (64,)]\n",
      "Dense weights shape: (16, 3), (3,)\n",
      "Initializing EmbeddingLayer with vocab_size=2796, embedding_dim=100, initializer=zeros\n",
      "Predicting with batch size: 32, input shape: (400, 100)\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 247,    7,  288,  ...,    0,    0,    0],\n",
      "        [ 495,  132,  534,  ...,    0,    0,    0],\n",
      "        [2236,   85,   26,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  14,    3,   20,  ...,    0,    0,    0],\n",
      "        [ 107,    1,    1,  ...,    0,    0,    0],\n",
      "        [ 534,  637, 1806,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    6,   43,  ...,    0,    0,    0],\n",
      "        [  28,  321,  181,  ...,    0,    0,    0],\n",
      "        [ 201,    5,    7,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  10, 1445,  438,  ...,    0,    0,    0],\n",
      "        [  32,   28,  157,  ...,    0,    0,    0],\n",
      "        [ 107,  570,  571,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   6,  316,   97,  ...,    0,    0,    0],\n",
      "        [ 293,    1, 1806,  ...,    0,    0,    0],\n",
      "        [  25,  107,  333,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 484,   80,  973,  ...,    0,    0,    0],\n",
      "        [   5,  118, 1011,  ...,    0,    0,    0],\n",
      "        [   5,  201,    7,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 713,  541,  726,  ...,    0,    0,    0],\n",
      "        [   5,    6,  201,  ...,    0,    0,    0],\n",
      "        [2736,  592,   45,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 807,  675,  682,  ...,    0,    0,    0],\n",
      "        [ 186, 1146, 1095,  ...,    0,    0,    0],\n",
      "        [   1,    2,    6,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[2487, 2616, 2618,  ...,    0,    0,    0],\n",
      "        [ 103,    1, 2582,  ...,    0,    0,    0],\n",
      "        [ 330,   25,    4,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  11, 1273,  775,  ...,    0,    0,    0],\n",
      "        [  92,  130,   11,  ...,    0,    0,    0],\n",
      "        [ 192,  139,  470,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 606,  273,    3,  ...,    0,    0,    0],\n",
      "        [  13,    9,    6,  ...,    0,    0,    0],\n",
      "        [  13,    9,  192,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  22, 1926,   37,  ...,    0,    0,    0],\n",
      "        [ 288,    9,   23,  ...,    0,    0,    0],\n",
      "        [  14,    3,   20,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[677,   6, 226,  ...,   0,   0,   0],\n",
      "        [ 67,   1, 258,  ...,   0,   0,   0],\n",
      "        [196,   1,   1,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  3, 108,  71,  ...,   0,   0,   0],\n",
      "        [151,  10,   3,  ...,   0,   0,   0],\n",
      "        [ 32, 157, 204,  ...,   0,   0,   0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  27,   12,   20,  ...,    0,    0,    0],\n",
      "        [ 422,    1, 1643,  ...,    0,    0,    0],\n",
      "        [ 973,    2,   28,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  200, 2195,  ...,    0,    0,    0],\n",
      "        [ 290,  146, 1428,  ...,    0,    0,    0],\n",
      "        [ 207,   23,    5,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 713,  541,  726,  ...,    0,    0,    0],\n",
      "        [   5,    6,  201,  ...,    0,    0,    0],\n",
      "        [2736,  592,   45,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 807,  675,  682,  ...,    0,    0,    0],\n",
      "        [ 186, 1146, 1095,  ...,    0,    0,    0],\n",
      "        [   1,    2,    6,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[2487, 2616, 2618,  ...,    0,    0,    0],\n",
      "        [ 103,    1, 2582,  ...,    0,    0,    0],\n",
      "        [ 330,   25,    4,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  11, 1273,  775,  ...,    0,    0,    0],\n",
      "        [  92,  130,   11,  ...,    0,    0,    0],\n",
      "        [ 192,  139,  470,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[ 606,  273,    3,  ...,    0,    0,    0],\n",
      "        [  13,    9,    6,  ...,    0,    0,    0],\n",
      "        [  13,    9,  192,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  22, 1926,   37,  ...,    0,    0,    0],\n",
      "        [ 288,    9,   23,  ...,    0,    0,    0],\n",
      "        [  14,    3,   20,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[677,   6, 226,  ...,   0,   0,   0],\n",
      "        [ 67,   1, 258,  ...,   0,   0,   0],\n",
      "        [196,   1,   1,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  3, 108,  71,  ...,   0,   0,   0],\n",
      "        [151,  10,   3,  ...,   0,   0,   0],\n",
      "        [ 32, 157, 204,  ...,   0,   0,   0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  27,   12,   20,  ...,    0,    0,    0],\n",
      "        [ 422,    1, 1643,  ...,    0,    0,    0],\n",
      "        [ 973,    2,   28,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  200, 2195,  ...,    0,    0,    0],\n",
      "        [ 290,  146, 1428,  ...,    0,    0,    0],\n",
      "        [ 207,   23,    5,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    2, 2226,  ...,    0,    0,    0],\n",
      "        [  99,    9,  216,  ...,    0,    0,    0],\n",
      "        [  37,    9,  165,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   5,   79,   10,  ...,    0,    0,    0],\n",
      "        [ 409,   30,   23,  ...,    0,    0,    0],\n",
      "        [   1,    1,    9,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  11,    1,  478,  ...,    0,    0,    0],\n",
      "        [ 317,   80,    9,  ...,    0,    0,    0],\n",
      "        [ 246, 1124,   18,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1,  372,  ...,    0,    0,    0],\n",
      "        [ 143,   21, 1447,  ...,    0,    0,    0],\n",
      "        [   1,   22,    1,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    9, 2749,  ...,    0,    0,    0],\n",
      "        [  27,    6,  338,  ...,    0,    0,    0],\n",
      "        [   1,    1,  143,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2531,  154,   29,  ...,    0,    0,    0],\n",
      "        [ 248,    7,    1,  ...,    0,    0,    0],\n",
      "        [ 560,  710,    1,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  13,  284,   75,  ...,    0,    0,    0],\n",
      "        [  19,    1,    1,  ...,    0,    0,    0],\n",
      "        [   5,   23,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  13, 2142,   96,  ...,    0,    0,    0],\n",
      "        [  54,  857,  121,  ...,    0,    0,    0],\n",
      "        [ 115,    1,    9,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  1, 322, 155,  ...,   0,   0,   0],\n",
      "        [807, 440, 480,  ...,   0,   0,   0],\n",
      "        [  1, 200, 754,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 67,  72,  13,  ...,   0,   0,   0],\n",
      "        [597,  97,  76,  ...,   0,   0,   0],\n",
      "        [125,  39,  91,  ...,   0,   0,   0]]), shape=torch.Size([16, 100]), data type=torch.int64\n",
      "Macro F1 Score: 0.1844\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    2, 2226,  ...,    0,    0,    0],\n",
      "        [  99,    9,  216,  ...,    0,    0,    0],\n",
      "        [  37,    9,  165,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   5,   79,   10,  ...,    0,    0,    0],\n",
      "        [ 409,   30,   23,  ...,    0,    0,    0],\n",
      "        [   1,    1,    9,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  11,    1,  478,  ...,    0,    0,    0],\n",
      "        [ 317,   80,    9,  ...,    0,    0,    0],\n",
      "        [ 246, 1124,   18,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1,  372,  ...,    0,    0,    0],\n",
      "        [ 143,   21, 1447,  ...,    0,    0,    0],\n",
      "        [   1,   22,    1,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[   1,    9, 2749,  ...,    0,    0,    0],\n",
      "        [  27,    6,  338,  ...,    0,    0,    0],\n",
      "        [   1,    1,  143,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2531,  154,   29,  ...,    0,    0,    0],\n",
      "        [ 248,    7,    1,  ...,    0,    0,    0],\n",
      "        [ 560,  710,    1,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  13,  284,   75,  ...,    0,    0,    0],\n",
      "        [  19,    1,    1,  ...,    0,    0,    0],\n",
      "        [   5,   23,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  13, 2142,   96,  ...,    0,    0,    0],\n",
      "        [  54,  857,  121,  ...,    0,    0,    0],\n",
      "        [ 115,    1,    9,  ...,    0,    0,    0]]), shape=torch.Size([32, 100]), data type=torch.int64\n",
      "Using EmbeddingLayer, converting indices to long tensor\n",
      "Forward pass in EmbeddingLayer with indices=tensor([[  1, 322, 155,  ...,   0,   0,   0],\n",
      "        [807, 440, 480,  ...,   0,   0,   0],\n",
      "        [  1, 200, 754,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 67,  72,  13,  ...,   0,   0,   0],\n",
      "        [597,  97,  76,  ...,   0,   0,   0],\n",
      "        [125,  39,  91,  ...,   0,   0,   0]]), shape=torch.Size([16, 100]), data type=torch.int64\n",
      "Macro F1 Score: 0.1844\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.layers import LSTM as TF_LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    TF_LSTM(units=16, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')  # for sentiment classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_padded,\n",
    "    train['label'].values,\n",
    "    validation_data=(valid_padded, valid['label'].values),\n",
    "    epochs=10,          # number of passes over the data, adjust as needed\n",
    "    batch_size=32,      # number of samples per batch, adjust as needed\n",
    "    verbose=0          # verbosity mode, 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_padded, test['label'])\n",
    "\n",
    "embedding_layer = model.layers[0]\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "lstm_layer = model.layers[1]\n",
    "lstm_weights = lstm_layer.get_weights()\n",
    "dense_layer = model.layers[3]\n",
    "dense_weights = dense_layer.get_weights()\n",
    "\n",
    "print(f\"Embedding weights shape: {embedding_weights.shape}\")\n",
    "print(f\"LSTM weights shape: {[w.shape for w in lstm_weights]}\")\n",
    "print(f\"Dense weights shape: {dense_weights[0].shape}, {dense_weights[1].shape}\")\n",
    "\n",
    "# Create LSTM model from scratch using custom implementation\n",
    "modelScratch = LSTM([\n",
    "    EmbeddingLayer(vocab_size, embedding_dim, 'zeros').load_weights(embedding_weights),\n",
    "    UnidirectionalLSTM(16, 100, 32, \"tanh\").load_weights(lstm_weights),\n",
    "    DenseLayer(3, 16, activation='softmax', init_method='zeros').load_weights(dense_weights)\n",
    "], 32)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(modelScratch, test_padded, test['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
